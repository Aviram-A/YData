{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsmut9mdsGAz",
        "outputId": "054dc44c-cd77-440d-aee7-7ca826798a3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.10/dist-packages (1.5.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchsummary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TR8ypGUpEcfg"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import os\n",
        "import copy\n",
        "from glob import glob\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchsummary import summary\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "import torch\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# Set random seeds\n",
        "def set_seed(seed=42):\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64r2lgLpZeuK"
      },
      "outputs": [],
      "source": [
        "# Set up the data folders. This requires the working directory to have the cell count zip file.\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "with zipfile.ZipFile('data/cell-dataset.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('.')\n",
        "\n",
        "for phase in ['train', 'val']:\n",
        "    for d in ['images', 'labels']:\n",
        "        if not os.path.isdir(f'./data/{phase}/{d}'):\n",
        "            os.makedirs(f'./data/{phase}/{d}')\n",
        "\n",
        "train_idxs = range(1,181) # Idx to use as train\\val\n",
        "val_idxs = range(181,201)\n",
        "\n",
        "\n",
        "for i in train_idxs:\n",
        "    full_num = str(i).zfill(3)\n",
        "    shutil.copy(f'./data/images/{full_num}cell.png', f'./data/train/images/{full_num}cell.png')\n",
        "    shutil.copy(f'./data/labels/{full_num}dots.png', f'./data/train/labels/{full_num}dots.png')\n",
        "\n",
        "for i in val_idxs:\n",
        "    full_num = str(i).zfill(3)\n",
        "    shutil.copy(f'./data/images/{full_num}cell.png', f'./data/val/images/{full_num}cell.png')\n",
        "    shutil.copy(f'./data/labels/{full_num}dots.png', f'./data/val/labels/{full_num}dots.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYMnz1XPmaeM"
      },
      "outputs": [],
      "source": [
        "# We tried a bunch of these normalizations but these worked best. Normalize might also help but we didn't have time to test it.\n",
        "def change_image_range(x):\n",
        "    return x / 255\n",
        "\n",
        "data_transforms = {\n",
        "    'train':\n",
        "    transforms.Compose([\n",
        "        change_image_range,\n",
        "        transforms.GaussianBlur(9),\n",
        "        transforms.RandomHorizontalFlip(0.5),\n",
        "        transforms.RandomVerticalFlip(0.5),\n",
        "        # transforms.Normalize(means, stds)\n",
        "        # transforms.ColorJitter(brightness=),\n",
        "        # transforms.ElasticTransform(),\n",
        "        # transforms.RandomRotation([torch.pi, -torch.pi/2, torch.pi/2], interpolation=transforms.InterpolationMode.BILINEAR),\n",
        "    ]),\n",
        "    'val':\n",
        "    transforms.Compose([\n",
        "        change_image_range,\n",
        "        # transforms.Normalize(means, stds)\n",
        "    ])\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ymhaOuKtLa3"
      },
      "outputs": [],
      "source": [
        "# Loads the dataset counting on the directory structure outlines above\n",
        "class CellsDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None, target_transform=None):\n",
        "\n",
        "        set_seed()\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "        self.data_paths = []\n",
        "\n",
        "        for image_path in glob(root_dir + '/images/*.png'):\n",
        "            image_name = image_path.split('/')[-1].split('cell')[0]\n",
        "            label_path = f'{root_dir}/labels/{image_name}dots.png'\n",
        "\n",
        "            if os.path.exists(f'{root_dir}/labels/{image_name}dots.png'):\n",
        "                self.data_paths.append((image_path, label_path))\n",
        "            else:\n",
        "                print('Missing label for', image_path)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "\n",
        "        img_path, label_path = self.data_paths[idx]\n",
        "\n",
        "        image = torchvision.io.read_image(img_path)\n",
        "        label = torchvision.io.read_image(label_path)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "\n",
        "        sample = (image, label)\n",
        "\n",
        "        return sample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUdywL9_Ek7l",
        "outputId": "2aa68b56-0d77-4f99-eb21-cfefd74d0425"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset_sizes:  {'train': 180, 'val': 20}\n"
          ]
        }
      ],
      "source": [
        "data_dir = r'./data'\n",
        "# Create a dictionary of train and val datasets from images in folders\n",
        "image_datasets = {x: CellsDataset(os.path.join(data_dir, x),\n",
        "                                  data_transforms[x],\n",
        "                                  target_transform=lambda x: x[0].sum() / 255\n",
        "                                  )\n",
        "                  for x in ['train', 'val']}\n",
        "\n",
        "\n",
        "dataloaders = {\n",
        "    'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=32,\n",
        "                                             shuffle=False, num_workers=2),\n",
        "    'val': torch.utils.data.DataLoader(image_datasets['val'], batch_size=32,\n",
        "                                          shuffle=False, num_workers=2)\n",
        "  }\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "print('dataset_sizes: ', dataset_sizes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12IWdPM15rPT",
        "outputId": "8f92f253-f503-4a1c-e90f-9398550ba8e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check for the availability of a GPU, and use CPU otherwise\n",
        "# If you are using Google Colab, be sure to change your runtime environment to GPU first.\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tb1_a4jGFmiw"
      },
      "outputs": [],
      "source": [
        "# A helper function to show an image from a tensor. We need to restore it to the original dynamic range before normalization\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    # mean = np.array(means)\n",
        "    # std = np.array(stds)\n",
        "    # inp = std * inp + mean\n",
        "    # inp = np.clip(inp, 0, 1)\n",
        "    fig = plt.figure(figsize=(5,3), dpi=300)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "       plt.title(title, fontsize=5)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "enWFqx2w_gHl"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    set_seed()\n",
        "    since = time.time()\n",
        "\n",
        "    # Init variables that will save info about the best model\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_mae = torch.inf\n",
        "\n",
        "    train_res= np.zeros((2,num_epochs))\n",
        "    val_res=np.zeros((2,num_epochs))\n",
        "    dict_res={'train':train_res, 'val':val_res}\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                # Set model to training mode.\n",
        "                model.train()\n",
        "            else:\n",
        "                # Set model to evaluate mode. In evaluate mode, we don't perform backprop and don't need to keep the gradients\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_ae = 0\n",
        "\n",
        "            # Iterate over data\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                # Prepare the inputs for GPU/CPU\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # ===== forward pass ======\n",
        "                with torch.set_grad_enabled(phase=='train'):\n",
        "                    # If we're in train mode, we'll track the gradients to allow back-propagation\n",
        "                    preds = model(inputs).squeeze() # apply the model to the inputs.\n",
        "                    loss = criterion(preds, labels)\n",
        "\n",
        "                    # ==== backward pass + optimizer step ====\n",
        "                    # This runs only in the training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward() # Perform a step in the opposite direction of the gradient\n",
        "                        optimizer.step() # Adapt the optimizer\n",
        "\n",
        "                # Collect statistics\n",
        "                running_loss += (loss.item() * inputs.size(0))\n",
        "                batch_ae = (preds - labels).abs().sum()\n",
        "                running_ae += batch_ae\n",
        "\n",
        "            if phase == 'train':\n",
        "                # Adjust the learning rate based on the scheduler\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_mae = running_ae / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} MAE: {epoch_mae:.4f}')\n",
        "\n",
        "            dict_res[phase][0,epoch]=epoch_loss\n",
        "            dict_res[phase][1,epoch]=epoch_mae\n",
        "\n",
        "            # Keep the results of the best model so far\n",
        "            if phase == 'val' and epoch_mae < best_mae:\n",
        "                best_mae = epoch_mae\n",
        "                # deepcopy the model\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {(time_elapsed // 60):.0f}m {(time_elapsed % 60):.0f}s')\n",
        "    print(f'Best val MAE: {best_mae:4f}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, dict_res,best_mae\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSdVTUp8Rj0y"
      },
      "outputs": [],
      "source": [
        "# Our network is completely made up. We also tried unet with added linear layers but it was hard to train and not as effective.\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        set_seed(42)\n",
        "        self.stuff = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(16),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(in_channels=16, out_channels=24, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(24),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(in_channels=24, out_channels=32, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(32),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2),\n",
        "                nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(64),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(128),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(256),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(512),\n",
        "                nn.ReLU(),\n",
        "                nn.MaxPool2d(kernel_size=2),\n",
        "                nn.Flatten(),\n",
        "                nn.Linear(64*64*512, 64),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(64, 1)\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        return self.stuff(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwXOGNkQRnDU",
        "outputId": "ded5804e-b284-48e1-d81c-092705516043"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 12500.5146 MAE: 88.7813\n",
            "val Loss: 29248.4785 MAE: 157.9612\n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 1580.4199 MAE: 30.3662\n",
            "val Loss: 25688.5977 MAE: 146.3291\n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 1500.0739 MAE: 32.9171\n",
            "val Loss: 13617.5342 MAE: 97.5603\n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 373.8204 MAE: 16.7142\n",
            "val Loss: 9629.6436 MAE: 77.7396\n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 532.4621 MAE: 17.6654\n",
            "val Loss: 4168.8267 MAE: 50.9891\n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 151.2976 MAE: 8.9666\n",
            "val Loss: 4195.9634 MAE: 51.0146\n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 242.4358 MAE: 12.5836\n",
            "val Loss: 2396.5696 MAE: 39.6073\n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 105.1125 MAE: 8.3944\n",
            "val Loss: 1972.6467 MAE: 34.9085\n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 164.1655 MAE: 10.2226\n",
            "val Loss: 743.1985 MAE: 22.2532\n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 69.6490 MAE: 6.4123\n",
            "val Loss: 460.1715 MAE: 16.6682\n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 101.6540 MAE: 7.8888\n",
            "val Loss: 115.7043 MAE: 8.4311\n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 50.1191 MAE: 5.3666\n",
            "val Loss: 72.2016 MAE: 6.4678\n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 75.1947 MAE: 6.9182\n",
            "val Loss: 48.0858 MAE: 5.1190\n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 49.3843 MAE: 5.3222\n",
            "val Loss: 32.5536 MAE: 4.1079\n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 38.1537 MAE: 4.6536\n",
            "val Loss: 32.0822 MAE: 3.9763\n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 45.5634 MAE: 5.3212\n",
            "val Loss: 27.7703 MAE: 4.2838\n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 39.9470 MAE: 4.3488\n",
            "val Loss: 36.3749 MAE: 4.3553\n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 34.4852 MAE: 4.7229\n",
            "val Loss: 37.9460 MAE: 4.5571\n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 57.7605 MAE: 5.9760\n",
            "val Loss: 128.6203 MAE: 9.3000\n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 37.2512 MAE: 4.8788\n",
            "val Loss: 61.1573 MAE: 6.7735\n",
            "\n",
            "Training complete in 2m 47s\n",
            "Best val MAE: 3.976259\n"
          ]
        }
      ],
      "source": [
        "model = Net()\n",
        "model = model.to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer_ft = optim.Adam(model.parameters(), lr=0.0001)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=40, gamma=0.1)\n",
        "num_epochs = 20\n",
        "\n",
        "model,dict_res,best_mae = train_model(model.to(device),\n",
        "                        dataloaders,\n",
        "                      criterion,\n",
        "                      optimizer_ft,\n",
        "                      exp_lr_scheduler,\n",
        "                      num_epochs=num_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atWU22pDmWV_"
      },
      "outputs": [],
      "source": [
        "# bst_lr = 0\n",
        "# bst_score = 120493\n",
        "# for learn in [0.00005,0.0001,0.0005]:\n",
        "#   model = Net()\n",
        "#   model = model.to(device)\n",
        "#   criterion = nn.MSELoss()\n",
        "#   optimizer_ft = optim.Adam(model.parameters(), lr=learn)  # reduce the learning rate\n",
        "#   exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=50, gamma=0.1)\n",
        "#   num_epochs = 50\n",
        "\n",
        "#   model,dict_res,best_mae = train_model(model.to(device),\n",
        "#                           dataloaders,\n",
        "#                         criterion,\n",
        "#                         optimizer_ft,\n",
        "#                         exp_lr_scheduler,\n",
        "#                         num_epochs=num_epochs)\n",
        "#   if best_mae < bst_score:\n",
        "#     bst_score = best_mae\n",
        "#     bst_lr = learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1IqjLuVaolx"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
